{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_questions = pd.read_hdf('auto_tagging_data_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learning?</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Mach...</td>\n",
       "      <td>[machine-learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\n...</td>\n",
       "      <td>[forecasting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain English</td>\n",
       "      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n",
       "      <td>[bayesian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>What is the meaning of p values and t values in statistical tests?</td>\n",
       "      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....</td>\n",
       "      <td>[hypothesis-testing, t-test, p-value, interpretation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Examples for teaching: Correlation does not mean causation</td>\n",
       "      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth ...</td>\n",
       "      <td>[correlation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                               Title  \\\n",
       "0   6                  The Two Cultures: statistics vs. machine learning?   \n",
       "1  21                                      Forecasting demographic census   \n",
       "2  22                 Bayesian and frequentist reasoning in plain English   \n",
       "3  31  What is the meaning of p values and t values in statistical tests?   \n",
       "4  36          Examples for teaching: Correlation does not mean causation   \n",
       "\n",
       "                                                                                                                                                                                                      Body  \\\n",
       "0  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Mach...   \n",
       "1  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\n...   \n",
       "2                                                                               <p>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?</p>\\n   \n",
       "3  <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....   \n",
       "4  <p>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:</p>\\n\\n<ol>\\n<li>number of storks and birth ...   \n",
       "\n",
       "                                                    Tags  \n",
       "0                                     [machine-learning]  \n",
       "1                                          [forecasting]  \n",
       "2                                             [bayesian]  \n",
       "3  [hypothesis-testing, t-test, p-value, interpretation]  \n",
       "4                                          [correlation]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine title and body\n",
    "df_questions['Text'] = df_questions[\"Title\"] + \" \" + df_questions[\"Body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove html tags and url links\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # remove everything alphabets\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
    "    # remove whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions['Text'] = df_questions['Text'].apply(lambda x: clean_text(x))\n",
    "df_questions['Text'] = df_questions['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43187</th>\n",
       "      <td>10526</td>\n",
       "      <td>canonical correlation analysis and time series analysis is there a way to utilize canonical correlation analysis when your data are time series and repeated measures i e your experimental units ar...</td>\n",
       "      <td>[time-series, correlation, multivariate-analysis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32755</th>\n",
       "      <td>88819</td>\n",
       "      <td>mcmc methods burning samples in mcmc methods i keep reading about burn in time or the number of samples to burn what is this exactly and why is it needed update once mcmc stabilizes does it remain...</td>\n",
       "      <td>[sampling, mcmc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73868</th>\n",
       "      <td>25908</td>\n",
       "      <td>how to determine the number of clusters when using correlation as the distance how does using correlation as the distance influence the determination of the number of clusters when doing kmeans is...</td>\n",
       "      <td>[r, correlation, clustering]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73742</th>\n",
       "      <td>167829</td>\n",
       "      <td>how do we decide on how to fill missing values in data i have a data set with na values in many predictor variables how do we impute the best values i have variables in total out of them belong to...</td>\n",
       "      <td>[regression]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17349</th>\n",
       "      <td>159496</td>\n",
       "      <td>testing for differences between populations of individuals with binomial data so i am trying to compare between populuations and determine whether there is a difference in count based data my data...</td>\n",
       "      <td>[hypothesis-testing, statistical-significance, anova, binomial]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  \\\n",
       "43187   10526   \n",
       "32755   88819   \n",
       "73868   25908   \n",
       "73742  167829   \n",
       "17349  159496   \n",
       "\n",
       "                                                                                                                                                                                                          Text  \\\n",
       "43187  canonical correlation analysis and time series analysis is there a way to utilize canonical correlation analysis when your data are time series and repeated measures i e your experimental units ar...   \n",
       "32755  mcmc methods burning samples in mcmc methods i keep reading about burn in time or the number of samples to burn what is this exactly and why is it needed update once mcmc stabilizes does it remain...   \n",
       "73868  how to determine the number of clusters when using correlation as the distance how does using correlation as the distance influence the determination of the number of clusters when doing kmeans is...   \n",
       "73742  how do we decide on how to fill missing values in data i have a data set with na values in many predictor variables how do we impute the best values i have variables in total out of them belong to...   \n",
       "17349  testing for differences between populations of individuals with binomial data so i am trying to compare between populuations and determine whether there is a difference in count based data my data...   \n",
       "\n",
       "                                                                  Tags  \n",
       "43187                [time-series, correlation, multivariate-analysis]  \n",
       "32755                                                 [sampling, mcmc]  \n",
       "73868                                     [r, correlation, clustering]  \n",
       "73742                                                     [regression]  \n",
       "17349  [hypothesis-testing, statistical-significance, anova, binomial]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions[['Id', 'Text', 'Tags']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Text to Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_questions['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81956"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique words count\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81957"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique words count\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df_questions['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the two cultures statistics vs machine learning last year i read a blog post from brendan o connor entitled statistics vs machine learning fight that discussed some of the differences between the two fields andrew gelman responded favorably to this simon blomberg from r s fortunes package to paraphrase provocatively machine learning is statistics minus any checking of models and assumptions brian d ripley about the difference between machine learning and statistics user vienna may season s greetings andrew gelman in that case maybe we should get rid of checking of models and assumptions more often then maybe we d be able to solve some of the problems that the machine learning people can solve but we can t there was also the statistical modeling the two cultures paper by leo breiman in which argued that statisticians rely too heavily on data modeling and that machine learning techniques are making progress by instead relying on the predictive accuracy of models has the statistics field changed over the last decade in response to these critiques do the two cultures still exist or has statistics grown to embrace machine learning techniques such as neural networks and support vector machines \n",
      "\n",
      "[1, 59, 9730, 255, 315, 482, 256, 577, 277, 2, 333, 3, 2733, 374, 36, 24159, 665, 20232, 9413, 255, 315, 482, 256, 12412, 11, 2734, 60, 5, 1, 441, 74, 1, 59, 2265, 3603, 3384, 5009, 18773, 4, 12, 6933, 50267, 36, 45, 34, 38034, 250, 4, 14051, 50268, 482, 256, 6, 255, 2548, 68, 1771, 5, 132, 7, 691, 9140, 70, 9568, 89, 1, 167, 74, 482, 256, 7, 255, 600, 21877, 264, 1580, 34, 10105, 3603, 3384, 8, 11, 143, 580, 54, 83, 103, 3655, 5, 1771, 5, 132, 7, 691, 92, 726, 81, 580, 54, 70, 19, 375, 4, 588, 60, 5, 1, 597, 11, 1, 482, 256, 320, 28, 588, 31, 54, 28, 17, 43, 97, 105, 1, 235, 772, 1, 59, 9730, 433, 55, 16689, 7210, 8, 47, 6113, 11, 3184, 3258, 427, 3024, 21, 13, 772, 7, 11, 482, 256, 865, 18, 912, 3570, 55, 424, 6334, 21, 1, 785, 406, 5, 132, 100, 1, 255, 1056, 1670, 186, 1, 577, 8085, 8, 234, 4, 94, 15913, 48, 1, 59, 9730, 330, 1223, 33, 100, 255, 6392, 4, 16690, 482, 256, 865, 164, 25, 478, 886, 7, 855, 270, 2100]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "print(df_questions['Text'][i], '\\n'), print(sequences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find right maximum length for the sequences__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = []\n",
    "\n",
    "for i in sequences:\n",
    "    seq_lengths.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th percentile:  97.0\n",
      "40th percentile:  116.0\n",
      "50th percentile:  137.0\n",
      "60th percentile:  162.0\n",
      "70th percentile:  193.0\n",
      "80th percentile:  238.0\n",
      "90th percentile:  320.0\n",
      "95th percentile:  411.0\n",
      "99th percentile:  678.0\n"
     ]
    }
   ],
   "source": [
    "print(\"30th percentile: \", pd.Series(seq_lengths).quantile(0.3))\n",
    "print(\"40th percentile: \", pd.Series(seq_lengths).quantile(0.4))\n",
    "print(\"50th percentile: \", pd.Series(seq_lengths).quantile(0.5))\n",
    "print(\"60th percentile: \", pd.Series(seq_lengths).quantile(0.6))\n",
    "print(\"70th percentile: \", pd.Series(seq_lengths).quantile(0.7))\n",
    "print(\"80th percentile: \", pd.Series(seq_lengths).quantile(0.8))\n",
    "print(\"90th percentile: \", pd.Series(seq_lengths).quantile(0.9))\n",
    "print(\"95th percentile: \", pd.Series(seq_lengths).quantile(0.95))\n",
    "print(\"99th percentile: \", pd.Series(seq_lengths).quantile(0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 125\n",
    "\n",
    "# padding\n",
    "padded_seq = pad_sequences(sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df_questions['Tags'])\n",
    "y = multilabel_binarizer.transform(df_questions['Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76365, 125), (76365, 100))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(padded_seq, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+1, 128, input_length = max_length))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Conv1D(300, 3, padding = 'valid', activation = \"relu\", strides = 1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(100, activation = \"sigmoid\"))\n",
    "#model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 125, 128)          10490624  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 125, 128)          0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 123, 300)          115500    \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 300)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,636,224\n",
      "Trainable params: 10,636,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(patience=3),ModelCheckpoint(filepath='model-conv1d_v1.h5', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "108/108 [==============================] - 93s 852ms/step - loss: 0.1858 - accuracy: 0.0473 - val_loss: 0.0905 - val_accuracy: 0.0615\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 86s 794ms/step - loss: 0.0893 - accuracy: 0.0674 - val_loss: 0.0871 - val_accuracy: 0.0851\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 87s 806ms/step - loss: 0.0836 - accuracy: 0.1163 - val_loss: 0.0800 - val_accuracy: 0.1390\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 84s 780ms/step - loss: 0.0749 - accuracy: 0.1987 - val_loss: 0.0706 - val_accuracy: 0.2439\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 85s 785ms/step - loss: 0.0671 - accuracy: 0.2633 - val_loss: 0.0652 - val_accuracy: 0.2787\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 84s 779ms/step - loss: 0.0621 - accuracy: 0.2944 - val_loss: 0.0612 - val_accuracy: 0.3011\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 84s 776ms/step - loss: 0.0584 - accuracy: 0.3150 - val_loss: 0.0586 - val_accuracy: 0.3273\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 84s 782ms/step - loss: 0.0556 - accuracy: 0.3357 - val_loss: 0.0569 - val_accuracy: 0.3342\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 83s 768ms/step - loss: 0.0536 - accuracy: 0.3498 - val_loss: 0.0557 - val_accuracy: 0.3430\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 84s 778ms/step - loss: 0.0518 - accuracy: 0.3632 - val_loss: 0.0548 - val_accuracy: 0.3460\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(x_train, y_train,epochs=10,batch_size=512,validation_split=0.1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Performane Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the code below to load the saved model\n",
    "# model = load_model('model-conv1d_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478/478 [==============================] - 7s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15273, 100)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set threshold to 0.45\n",
    "preds_int = (preds >= 0.45).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47293110476966976"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# calculate F1 score\n",
    "f1_score(y_val, preds_int, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('model-conv1d_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tags(q):\n",
    "    q = clean_text(q)\n",
    "    q = q.lower()\n",
    "    q_seq = tokenizer.texts_to_sequences([q])\n",
    "    q_seq_padded = pad_sequences(q_seq, maxlen=300)\n",
    "    q_pred = model.predict(q_seq_padded)\n",
    "    q_pred = (q_pred >= 0.3).astype(int)\n",
    "    return multilabel_binarizer.inverse_transform(q_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 279ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('data-visualization', 'r')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give new question\n",
    "new_q = \"Regression line in ggplot doesn't match computed regression Im using R and created a chart using ggplot2. I then create a regression so I can make some predicitions I pass my data frame of to the predict function predict(regression, Measures) I'd expect the predictions to be the same as if I used the regression line on the chart, but they aren't the same. Why would this be the case? Is there a setting in ggplot or is my expectation incorrect?\"\n",
    "\n",
    "newq= \"Including -Inf on ggplot2 axis\"\n",
    "# get tags\n",
    "infer_tags(newq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9321091b4504c222f29c630232bebbbfda669e2e4d0f632bfa597d159cf9e956"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
